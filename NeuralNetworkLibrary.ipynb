{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "3JDc_vCt4Lkj"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C1ATJTpO4zb_",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# FUNCIONES DE ACTIVACION Y SUS DERIVADAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4g19AzOYTXYc",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Clases de cada funcion (contiene su funcion y su derivada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "AmUUjdrl4qSr"
   },
   "outputs": [],
   "source": [
    "class activationFunction:\n",
    "    \"\"\"\n",
    "    Class for activation functions meant to be used on Neural Networks\n",
    "    All the activation functions and its derivatives are available on the subclases\n",
    "    Subclasses:\n",
    "    Swish()\n",
    "    Relu()\n",
    "    Purelin()\n",
    "    Logsig()\n",
    "    Tansig()\n",
    "    Radbas()\n",
    "    Tribas()\n",
    "    RadBasN()\n",
    "    HardLim()\n",
    "    HardLims()\n",
    "    SatLin()\n",
    "    SatLins()\n",
    "    Softmax()\n",
    "    LeakyRelu()\n",
    "    ELU()\n",
    "    GELU()\n",
    "    PReLU()\n",
    "    SELU()\n",
    "    SiLU()\n",
    "    Softplus()\n",
    "    \"\"\"\n",
    "    def function(self,x):\n",
    "        \"\"\"Activation function\"\"\"\n",
    "        raise NotImplementedError(\"This is only the base function, the implementation of this is on any of the other functions, for more information check the class DOCSTRING\")\n",
    "    def derivative(self,x):\n",
    "        \"\"\"Derivative of the activation function\"\"\"\n",
    "        raise NotImplementedError(\"This is only the base function, the implementation of this is on any of the other functions, for more information check the class DOCSTRING\")\n",
    "    def active(self):\n",
    "        raise NotImplementedError(\"This is only the base function, the implementation of this is on any of the other functions, for more information check the class DOCSTRING\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "vl52Q1Rl4sbo"
   },
   "outputs": [],
   "source": [
    "class Swish(activationFunction):\n",
    "    \"\"\"Scaled Exponential Linear Unit With a Shift function\"\"\"\n",
    "    def __init__(self, beta=1):\n",
    "        self.beta = beta\n",
    "    def function(self, x):\n",
    "        return x * (1 / (1 + np.exp(-self.beta * x)))\n",
    "    def derivative(self, x):\n",
    "        return (self.beta * self.function(x)) + (1 / (1 + np.exp(-self.beta * x))) * (1 - self.beta * self.function(x))\n",
    "    def active(self):\n",
    "        out = [-float('inf'), float('inf')]\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "8shE1T3W4yJz"
   },
   "outputs": [],
   "source": [
    "class Relu(activationFunction):\n",
    "    \"\"\"Rectified linear unit function (ReLU)\"\"\"\n",
    "    def function(self, x):\n",
    "        return np.maximum(0,x)\n",
    "    def derivative(self, x):\n",
    "        return np.where(x>0,1,0)\n",
    "    def active(self):\n",
    "        out = [0, float('inf')]\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "j2v-Y_2495Yb"
   },
   "outputs": [],
   "source": [
    "class Purelin(activationFunction):\n",
    "    \"\"\"Linear (Identity) function\"\"\"\n",
    "    def function(self,x):\n",
    "      return x\n",
    "    def derivative(self,x):\n",
    "      return np.ones_like(x)\n",
    "    def active(self):\n",
    "        out = [-float('inf'), float('inf')]\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "KuoUYoUuIG6P"
   },
   "outputs": [],
   "source": [
    "class Logsig(activationFunction):\n",
    "    \"\"\"Logistic function\"\"\"\n",
    "    def function(self, x):\n",
    "      return 1 / (1 + np.exp(-x))\n",
    "    def derivative(self,x):\n",
    "        return self.function(x) * (1 - self.function(x))\n",
    "    def active(self):\n",
    "        out = [-4.0, 4.0]\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "FbhNfFvmI9Cd"
   },
   "outputs": [],
   "source": [
    "class Tansig(activationFunction):\n",
    "    \"\"\"Hyperbolic function\"\"\"\n",
    "    def function(self,x):\n",
    "        return np.tanh(x)\n",
    "    def derivative(self,x):\n",
    "        return  1- np.tanh(x)**2\n",
    "    def active(self):\n",
    "        out = [-2, 2]\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "jIZd2WWFKioZ"
   },
   "outputs": [],
   "source": [
    "class Radbas(activationFunction):\n",
    "    \"\"\"Gaussian function\"\"\"\n",
    "    def function(self,x):\n",
    "        return np.exp(-x**2)\n",
    "    def derivative(self,x):\n",
    "        return -2 * x * np.exp(-x**2)\n",
    "    def active(self):\n",
    "        out = [-2, 2]\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "UTE_IxFnLIkU"
   },
   "outputs": [],
   "source": [
    "class Tribas(activationFunction):\n",
    "    \"\"\"Triangular basis function\"\"\"\n",
    "    def function(self, x):\n",
    "      return np.maximum(0, 1 - np.abs(x))\n",
    "    def derivative(self, x):\n",
    "      return np.where(np.abs(x) < 1, -1, 0)\n",
    "    def active(self):\n",
    "        out = [-1, 1]\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "lgC1nhgnLjeX"
   },
   "outputs": [],
   "source": [
    "class RadBasN(activationFunction):\n",
    "    \"\"\"Normalized radial basis function\"\"\"\n",
    "    def __init__(self, sigma=1):\n",
    "        \"\"\"\n",
    "        PARAMETERS\n",
    "        sigma : float by default 1\n",
    "        \"\"\"\n",
    "        self.sigma = sigma\n",
    "\n",
    "    def function(self, x):\n",
    "      return np.exp(-0.5 * (x / self.sigma)**2)\n",
    "    def derivative(self, x):\n",
    "      return -x / self.sigma**2 * np.exp(-0.5 * (x / self.sigma)**2)\n",
    "    def active(self):\n",
    "        out = [-2, 2]\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "yhHg-ZxGNLkp"
   },
   "outputs": [],
   "source": [
    "class HardLim(activationFunction):\n",
    "    \"\"\"Hard limit function\"\"\"\n",
    "    def function(self, x):\n",
    "        return np.where(x >= 0, 1, 0)\n",
    "    def derivative(self, x):\n",
    "        return np.zeros_like(x)\n",
    "    def active(self):\n",
    "        out = [0, 0]\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "Vx0uAWHENjcZ"
   },
   "outputs": [],
   "source": [
    "class HardLims(activationFunction):\n",
    "    \"\"\"Symmetric hard limit function\"\"\"\n",
    "    def function(self, x):\n",
    "        return np.where(x >= 0, 1, -1)\n",
    "    def derivative(self, x):\n",
    "        return np.zeros_like(x)\n",
    "    def active(self):\n",
    "        out = [0, 0]\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "s44mofomN2ju"
   },
   "outputs": [],
   "source": [
    "class SatLin(activationFunction):\n",
    "    \"\"\"Saturatin linear function\"\"\"\n",
    "    def function(self, x):\n",
    "        return np.clip(x, 0, None)\n",
    "\n",
    "    def derivative(self, x):\n",
    "        return np.where(x >= 0, 1, 0)\n",
    "    \n",
    "    def active(self):\n",
    "        out = [-0, 1]\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "3W5XynwgN-wb"
   },
   "outputs": [],
   "source": [
    "class SatLins(activationFunction):\n",
    "    \"\"\"Symmetric saturating function\"\"\"\n",
    "    def function(self, x):\n",
    "        return np.clip(x, -1, 1)\n",
    "\n",
    "    def derivative(self, x):\n",
    "        return np.where(np.logical_and(x >= -1, x <= 1), 1, 0)\n",
    "    \n",
    "    def active(self):\n",
    "        out = [-1, 1]\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "ra-GQVY6Pm9-"
   },
   "outputs": [],
   "source": [
    "class Softmax(activationFunction):\n",
    "    \"\"\"Normalized exponential function (softmax)\"\"\"\n",
    "    def function(self, x):\n",
    "        exps = np.exp(x)\n",
    "        sums = np.sum(exps)\n",
    "        return np.divide(exps, sums)\n",
    "    \n",
    "    def derivative(self, x):\n",
    "        raise NotImplementedError(\"La derivada de Softmax no se utiliza típicamente en el entrenamiento de redes neuronales.\")\n",
    "    \n",
    "    def active(self):\n",
    "        out = [-float('inf'), float('inf')]\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "pNnzzwWtP2yO"
   },
   "outputs": [],
   "source": [
    "class LeakyRelu(activationFunction):\n",
    "    \"\"\"Leaky rectified linear unit function (leakyRelu)\"\"\"\n",
    "    def function(self, x):\n",
    "        return np.where(x>0,x,1e-2*x)\n",
    "    def derivative(self, x):\n",
    "        return np.where(x>0,1,1e-2)\n",
    "    def active(self):\n",
    "        out = [-float('inf'), float('inf')]\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "Kj60iC_mP5aR"
   },
   "outputs": [],
   "source": [
    "class ELU(activationFunction):\n",
    "    \"\"\"Exponential Linear Unit function (ELU)\"\"\"\n",
    "    def __init__(self, alpha=1):\n",
    "        \"\"\"\n",
    "        PARAMETERS:\n",
    "        alpha = float by default 1\n",
    "        \"\"\"\n",
    "        self.alpha=alpha\n",
    "    def function(self, x):\n",
    "        return np.where(x>0,x,self.alpha*(np.exp(x)-1))\n",
    "    def derivative(self, x):\n",
    "        return np.where(x>0,1,self.alpha*np.exp(x))\n",
    "    def active(self):\n",
    "        out = [-float('inf'), float('inf')]\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "mpJ1CbgVP8hu"
   },
   "outputs": [],
   "source": [
    "class GELU(activationFunction):\n",
    "    \"\"\"Gaussian Error Linear Unit function (GELU)\"\"\"\n",
    "    def function(self, x):\n",
    "        return 0.5 * x * (1 + erf(x / np.sqrt(2)))\n",
    "    def derivative(self, x):\n",
    "        return 0.5 * (1 + erf(x / np.sqrt(2))) + (x / np.sqrt(2 * np.pi)) * np.exp(-0.5 * x**2)\n",
    "    def active(self):\n",
    "        out = [-float('inf'), float('inf')]\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "I0lFxTdgP-w9"
   },
   "outputs": [],
   "source": [
    "class PReLU(activationFunction):\n",
    "    \"\"\"Parametric rectified linear unit function (PReLU)\"\"\"\n",
    "    def __init__(self, alpha=1e-1):\n",
    "        \"\"\"\n",
    "        PARAMETERS\n",
    "        alpha : float by default 1e-1\n",
    "        \"\"\"\n",
    "        self.alpha=alpha\n",
    "    def function(self, x):\n",
    "        return np.where(x<0,self.alpha*x,x)\n",
    "    def derivative(self, x):\n",
    "        return np.where(x<0,self.alpha,1)\n",
    "    def active(self):\n",
    "        out = [-float('inf'), float('inf')]\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "Zfu4-hwtQAcV"
   },
   "outputs": [],
   "source": [
    "class SELU(activationFunction):\n",
    "    \"\"\"Scaled exponential linear unit function (SELU)\"\"\"\n",
    "    def __init__(self, lamb= 1.0507, alpha=1.67326):\n",
    "        \"\"\"\n",
    "        PARAMETERS\n",
    "        lamb : float by default 1.0507\n",
    "        alpha : float by default 1.67326\n",
    "        Both are suposed to be always that value so it's recomended to not change them\n",
    "        \"\"\"\n",
    "        self.lamb=lamb\n",
    "        self.alpha=alpha\n",
    "    def function(self, x):\n",
    "        return self.lamb * np.where(x<0, self.alpha*(np.exp(x)-1),x)\n",
    "    def derivative(self, x):\n",
    "        return self.lamb * np.where(x<0, self.alpha*np.exp(x),1)\n",
    "    def active(self):\n",
    "        out = [-float('inf'), float('inf')]\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "iw1z8DEkQC5j"
   },
   "outputs": [],
   "source": [
    "class SiLU(activationFunction):\n",
    "    \"\"\"Sigmoid linear unit function (SiLU)\"\"\"\n",
    "    def function(self, x):\n",
    "        return (x / (1 + np.exp(-x)))\n",
    "    def derivative(self, x):\n",
    "        return (1 + np.exp(-x) + x*np.exp(-x))/((1+np.exp(-x))**2)\n",
    "    def active(self):\n",
    "        out = [-float('inf'), float('inf')]\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "CIoQz-TqQFLg"
   },
   "outputs": [],
   "source": [
    "class Softplus(activationFunction):\n",
    "    \"\"\"Smooth approximation ReLU function\"\"\"\n",
    "    def function(self, x):\n",
    "        return np.log(1 + np.exp(x))\n",
    "    def derivative(self, x):\n",
    "        return 1 / (1+np.exp(-x))\n",
    "    def active(self):\n",
    "        out = [-float('inf'), float('inf')]\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Funciones de error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ErrorFunctions:\n",
    "    @staticmethod\n",
    "    def MSE(y_true, y_pred):\n",
    "        \"\"\"\n",
    "        Calculate the mean squared error between true and predicted values.\n",
    "\n",
    "        Parameters:\n",
    "        y_true: numpy.ndarray\n",
    "            True values\n",
    "        y_pred: numpy.ndarray\n",
    "            Predicted values\n",
    "\n",
    "        Returns:\n",
    "        float\n",
    "            Mean squared error\n",
    "        \"\"\"\n",
    "        y_true = np.array(y_true)\n",
    "        y_pred = np.array(y_pred)\n",
    "        return np.mean((y_true - y_pred) ** 2)\n",
    "    \n",
    "    @staticmethod\n",
    "    def MAE(y_true, y_pred):\n",
    "        \"\"\"\n",
    "        Calculate the mean absolute error between true and predicted values.\n",
    "\n",
    "        Parameters:\n",
    "        y_true: numpy.ndarray\n",
    "            True values\n",
    "        y_pred: numpy.ndarray\n",
    "            Predicted values\n",
    "\n",
    "        Returns:\n",
    "        float\n",
    "            Mean absolute error\n",
    "        \"\"\"\n",
    "        y_true = np.array(y_true)\n",
    "        y_pred = np.array(y_pred)\n",
    "        return np.mean(np.abs(y_true - y_pred))\n",
    "\n",
    "    @staticmethod\n",
    "    def SSE(y_true, y_pred):\n",
    "        \"\"\"\n",
    "        Calculate the sum of squared errors between true and predicted values.\n",
    "\n",
    "        Parameters:\n",
    "        y_true: numpy.ndarray\n",
    "            True values\n",
    "        y_pred: numpy.ndarray\n",
    "            Predicted values\n",
    "\n",
    "        Returns:\n",
    "        float\n",
    "            Sum of squared errors\n",
    "        \"\"\"\n",
    "        y_true = np.array(y_true)\n",
    "        y_pred = np.array(y_pred)\n",
    "        return np.sum((y_true - y_pred) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QFBX6lkR44kf"
   },
   "source": [
    "# ESTRUCTURA DE LA RED NEURONAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    \"\"\"Class for the structure of a Neural Network\"\"\"\n",
    "    def __init__(self, input_size, layer_sizes, output_size, activation_funcs, wInit='random'):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        input_size: int \n",
    "            Defines the size of the input layer\n",
    "        layer_sizes: int array \n",
    "            Defines the sizes of the ocult layers\n",
    "        output_size: int \n",
    "            Defines the size of the output layer\n",
    "        activation_funcs: activationFunction class array \n",
    "            Defines the activation function per layer\n",
    "        \"\"\"\n",
    "        self.input_size = input_size\n",
    "        self.layer_sizes = [input_size] + layer_sizes + [output_size]  # Incluir el tamaño de la capa de entrada y de salida\n",
    "        self.output_size = output_size\n",
    "        self.activation_funcs = activation_funcs\n",
    "\n",
    "        self.num_layers = len(self.layer_sizes)\n",
    "        self.weights = self._initializeWeights(wInit)\n",
    "        self.n_outputs = []  # Lista para almacenar las salidas antes de la función de activación\n",
    "        self.a_outputs = []\n",
    "    \n",
    "    def _initializeWeights(self, wInit):\n",
    "        \"\"\"\n",
    "        Inicializa los pesos de la red neuronal ya sea de manera random o mediante el metodo nguyen widraw\n",
    "        \n",
    "        :return: Lista de matrices de pesos como np.ndarrar\n",
    "        \"\"\"\n",
    "        weights = []\n",
    "        if wInit == 'random':\n",
    "            for i in range(self.num_layers - 1):\n",
    "                W = np.random.randn(self.layer_sizes[i] + 1, self.layer_sizes[i+1]) # +1 para incluir los sesgos\n",
    "                weights.append(W)\n",
    "        elif wInit == 'nguyen':\n",
    "            for i in range(self.num_layers - 1):\n",
    "                ni = self.layer_sizes[i]\n",
    "                no = self.layer_sizes[i+1]\n",
    "                g = (0.7*no) ** (1/ni)\n",
    "                active = self.activation_funcs[i].active()\n",
    "                if not np.isinf(active[0]) and not np.isinf(active[1]):\n",
    "                    W = np.random.randn(no, ni)\n",
    "                    W = W / np.linalg.norm(W, axis=1, keepdims=True)  # Normalize\n",
    "                    W = g * W\n",
    "                    # Compute bias based on active range\n",
    "                    beta = np.linspace(active[0], active[1], no).reshape(-1, 1)\n",
    "                    bias = g * (np.sign(W[:, 0]).reshape(-1, 1) * beta)\n",
    "                    W = np.hstack([W, bias])\n",
    "                    weights.append(W.T)\n",
    "                else:\n",
    "                    W = g * np.random.randn(ni+1,no)\n",
    "                    weights.append(W)\n",
    "        else:\n",
    "            raise KeyError(\"No se reconoce el inicializador\")\n",
    "        return np.array(weights, dtype = object)\n",
    "    \n",
    "    def forwardPass(self, inputs):\n",
    "        A = np.hstack([inputs,np.ones((inputs.shape[0], 1))])\n",
    "        self.n_outputs = [inputs] #La primera n siempre es igual a los inputs\n",
    "        self.a_outputs = [A]\n",
    "        # Iterar sobre cada capa de la red\n",
    "        for weight in self.weights:\n",
    "            # Cálculo del producto punto entre los pesos y el input aumentado por el sesgo\n",
    "            Z = np.dot(A,weight)\n",
    "            self.n_outputs.append(Z)\n",
    "            # Aplicación de la función de activación correspondiente\n",
    "            A = self.activation_funcs[len(self.a_outputs)-1].function(Z)\n",
    "            A = np.hstack([A,np.ones((A.shape[0], 1))])\n",
    "            self.a_outputs.append(A)  \n",
    "        return A[:,:-1] # TODO MENOS LA COLUMNA AUMENTADA\n",
    "\n",
    "    def backwardPass(self, targets):\n",
    "        #gradients = np.array([])\n",
    "        gradients = []\n",
    "        e = targets - self.a_outputs[-1][:,:-1]\n",
    "        ge = -2*e\n",
    "        delta = ge * self.activation_funcs[-1].derivative(np.array(self.n_outputs[-1]))\n",
    "        ae = self.a_outputs[-2] #El metodo forward pass deja a_outputs aumentado\n",
    "        ge = np.dot(ae.T,delta)\n",
    "        #ge = delta * ae.T\n",
    "        #gradients = np.concatenate((ge.flatten(),gradients))\n",
    "        gradients.append(ge)\n",
    "        \n",
    "        for i in range(self.num_layers-2, 0, -1): \n",
    "            fdx = self.activation_funcs[i].derivative(np.array(self.n_outputs[i]))\n",
    "            delta = fdx * np.dot(delta,self.weights[i][:-1].T)\n",
    "            ae = self.a_outputs[i-1]\n",
    "            ge = np.dot(ae.T,delta)\n",
    "            gradients.insert(0,ge)\n",
    "            #gradients = np.concatenate((ge.flatten(),gradients))            \n",
    "        return gradients\n",
    "            \n",
    "    def error(self,targets,error_func):\n",
    "        \"\"\"\n",
    "        Calculate the error based on the inputs, outputs, and error function specified.\n",
    "\n",
    "        Parameters:\n",
    "        inputs: numpy.ndarray\n",
    "            Input data\n",
    "        outputs: numpy.ndarray\n",
    "            Output data\n",
    "        error_func: function\n",
    "            Error function to use (e.g., mean squared error, mean absolute error, etc.)\n",
    "\n",
    "        Returns:\n",
    "        float\n",
    "            Error value calculated using the specified error function.\n",
    "        \"\"\"\n",
    "        predicted_outputs = self.a_outputs[-1][:,:-1]\n",
    "        return error_func(targets, predicted_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Optimizadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer():\n",
    "    \"\"\"\n",
    "    Class for the optimizers based on two different algorithms\n",
    "\n",
    "    RMSProp()\n",
    "    AdamW() \n",
    "    \"\"\"\n",
    "    def __init__(self,lr:float,maxEpochs:int,goal:float,mingrad:float,nn: NeuralNetwork,\n",
    "                 inputs,targets,error_fun,show:int =1,consecutive_epochs:int =10,\n",
    "                 num_batch: int=1)->None:  \n",
    "        self.nn = nn\n",
    "        self.name = \"DEFAULT\"\n",
    "        self.lr = lr\n",
    "        self.num_batch = num_batch\n",
    "        self.maxEpochs = maxEpochs\n",
    "        self.goal = goal\n",
    "        self.mingrad = mingrad\n",
    "        self.show = show\n",
    "        self.inputs = inputs\n",
    "        self.targets = targets\n",
    "        self.error_fun = error_fun\n",
    "        self.consecutive_epochs = consecutive_epochs\n",
    "        \n",
    "        \n",
    "    def optimize(self):\n",
    "        this = self.name\n",
    "        stop = \"\"\n",
    "        epochs = []\n",
    "        perfs  = []\n",
    "        consecutive_rise = 0  # Contador para el número de épocas consecutivas en las que el rendimiento ha subido\n",
    "        prev_perf = float('inf')\n",
    "        print(\"\\n\")\n",
    "        # Train\n",
    "        for epoch in range(self.maxEpochs+1):\n",
    "            # Performance and Gradient\n",
    "            _ = self.nn.forwardPass(self.inputs)\n",
    "            gX = self.nn.backwardPass(self.targets)\n",
    "            perf = self.nn.error(self.targets, self.error_fun)            \n",
    "            \n",
    "            # Aplanar y concatenar los gradientes en un solo vector\n",
    "            gX_flattened = np.concatenate([grad.flatten() for grad in gX])\n",
    "            normgX = np.linalg.norm(gX_flattened)  \n",
    "            #normgX = np.linalg.norm(gX)  \n",
    "            \n",
    "            # Stopping criteria\n",
    "            if np.all(perf <= self.goal):\n",
    "                stop = \"Performance goal met\"\n",
    "            elif epoch == self.maxEpochs:\n",
    "                stop = \"Maximum epoch reached, performance goal was not met\"\n",
    "            elif normgX < self.mingrad:\n",
    "                stop = \"Minimum gradient reached, performance goal was not met\"\n",
    "            elif perf >= prev_perf:\n",
    "                consecutive_rise += 1\n",
    "                if consecutive_rise >= self.consecutive_epochs:\n",
    "                    stop = f\"Performance has risen for {self.consecutive_epochs} consecutive epochs\"\n",
    "            elif perf < prev_perf:\n",
    "                consecutive_rise = 0\n",
    "    \n",
    "            prev_perf = perf\n",
    "\n",
    "            # Progress\n",
    "            if (np.fmod(epoch,self.show) == 0 or len(stop) != 0):\n",
    "                print(this,end = \": \")\n",
    "                if np.isfinite(self.maxEpochs):\n",
    "                    print(\"Epoch \",epoch, \"/\", self.maxEpochs,end = \" \")\n",
    "                if np.isfinite(self.goal):\n",
    "                    print(\", Performance %8.3e\" % perf, \"/\", self.goal, end = \" \")\n",
    "                if np.isfinite(self.mingrad):\n",
    "                    print(\", Gradient %8.3e\" % normgX, \"/\", self.mingrad)\n",
    "\n",
    "                \n",
    "                if len(stop) != 0:\n",
    "                    print(\"\\n\",this,\":\",stop,\"\\n\")\n",
    "                    break\n",
    "            epochs = np.append(epochs,epoch)\n",
    "            perfs = np.append(perfs,perf)\n",
    "            self.train(gX_flattened)\n",
    "            \n",
    "        return perfs, epochs\n",
    "    def train(self,gX):\n",
    "        raise NotImplementedError(\"No se ha definido el optimizador, esta es la clase base\")\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RmsProp(Optimizer):\n",
    "    def __init__(self, nn: NeuralNetwork, inputs, targets,lr: float =1e-3, num_batch: int =1, maxEpochs: int =500, \n",
    "                 goal: float =1e-8,mingrad: float =1e-11, show:int =1, error_fun=ErrorFunctions.SSE, \n",
    "                 consecutive_epochs: int=10,WDecay:float=0,alpha:float=0.99,centered:bool=False,\n",
    "                 momentum:float=0.6,epsilon:float=1e-9) -> None:\n",
    "        super().__init__(lr,maxEpochs,goal,mingrad,nn,inputs,targets,error_fun,show,consecutive_epochs,num_batch)\n",
    "        self.name = \"trainRMSPROP\"\n",
    "        self.epsilon = epsilon\n",
    "        self.v = np.zeros_like(np.concatenate([w.flatten() for w in nn.weights]))  # Vector de acumulación de gradientes\n",
    "        self.vh = 0\n",
    "        self.b = 0\n",
    "        self.gAvg = 0\n",
    "        self.WDecay = WDecay\n",
    "        self.alpha = alpha\n",
    "        self.centered = centered\n",
    "        self.momentum = momentum\n",
    "\n",
    "    def train(self, gX):        \n",
    "        if self.WDecay != 0:\n",
    "            gX = gX + gX*self.WDecay\n",
    "        self.v = self.alpha*self.v + ((1-self.alpha)*(gX**2))\n",
    "        self.vh = self.v\n",
    "        if self.centered:\n",
    "            self.gAvg = self.gAvg*self.alpha + ((1-self.alpha)*gX)\n",
    "            self.vh = self.vh - self.gAvg**2\n",
    "        if self.momentum > 0:\n",
    "            self.b = self.momentum*self.b + gX/((self.vh**(1/2))+self.epsilon)\n",
    "            update = self.lr*self.b\n",
    "            #self.nn.weights += dX\n",
    "        else:\n",
    "            update = self.lr*(gX/((self.vh**(1/2))+1e-8))\n",
    "            #self.nn.weights += dX\n",
    "        \n",
    "        # Actualizar pesos\n",
    "        start = 0\n",
    "        for i, w in enumerate(self.nn.weights):\n",
    "            shape = w.shape\n",
    "            size = np.prod(shape)\n",
    "            grad_update = update[start:start+size].reshape(shape)\n",
    "            self.nn.weights[i] -= grad_update\n",
    "            start += size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "\n",
    "def main():\n",
    "    activationFunction()\n",
    "    neural_network = NeuralNetwork(input_size = 2,\n",
    "                                layer_sizes = [50,50,30],\n",
    "                                output_size = 2,\n",
    "                                activation_funcs = [Logsig(),Logsig(),Relu(),Purelin()],\n",
    "                                wInit = 'nguyen')\n",
    "\n",
    "    # Carga el archivo .mat\n",
    "    data = loadmat('engine_dataset.mat')\n",
    "    inputs = data['engineInputs'].T\n",
    "    targets = data['engineTargets'].T\n",
    "    for weight in neural_network.weights:\n",
    "        print(f\"Tamano de los pesos: {weight.shape}\")\n",
    "    \n",
    "    Optimizador = RmsProp(nn=neural_network,\n",
    "                          inputs=inputs,\n",
    "                          targets=targets,\n",
    "                          lr=1e-2,\n",
    "                          maxEpochs=10000,\n",
    "                          show=500,\n",
    "                          consecutive_epochs=10,\n",
    "                          mingrad=1e-8,\n",
    "                          error_fun=ErrorFunctions.SSE)\n",
    "    \n",
    "    perfs,epochs = Optimizador.optimize()\n",
    "    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(epochs, perfs)\n",
    "    plt.title('Performance')\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    #print(f\"Pesos despues: {neural_network.weights}\")\n",
    "    outputs = neural_network.forwardPass(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DO MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamano de los pesos: (3, 50)\n",
      "Tamano de los pesos: (51, 50)\n",
      "Tamano de los pesos: (51, 30)\n",
      "Tamano de los pesos: (31, 2)\n",
      "\n",
      "\n",
      "trainRMSPROP: Epoch  0 / 10000 , Performance 2.524e+09 / 1e-08 , Gradient 4.779e+08 / 1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_5436\\3040260320.py:4: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainRMSPROP: Epoch  183 / 10000 , Performance 6.209e+08 / 1e-08 , Gradient 2.584e-07 / 1e-08\n",
      "\n",
      " trainRMSPROP : Performance has risen for 10 consecutive epochs \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
