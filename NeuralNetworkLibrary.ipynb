{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "3JDc_vCt4Lkj"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C1ATJTpO4zb_",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# FUNCIONES DE ACTIVACION Y SUS DERIVADAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4g19AzOYTXYc",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Clases de cada funcion (contiene su funcion y su derivada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "AmUUjdrl4qSr"
   },
   "outputs": [],
   "source": [
    "class activationFunction:\n",
    "    \"\"\"\n",
    "    Class for activation functions meant to be used on Neural Networks\n",
    "    All the activation functions and its derivatives are available on the subclases\n",
    "    Subclasses:\n",
    "    Swish()\n",
    "    Relu()\n",
    "    Purelin()\n",
    "    Logsig()\n",
    "    Tansig()\n",
    "    Radbas()\n",
    "    Tribas()\n",
    "    RadBasN()\n",
    "    HardLim()\n",
    "    HardLims()\n",
    "    SatLin()\n",
    "    SatLins()\n",
    "    Softmax()\n",
    "    LeakyRelu()\n",
    "    ELU()\n",
    "    GELU()\n",
    "    PReLU()\n",
    "    SELU()\n",
    "    SiLU()\n",
    "    Softplus()\n",
    "    \"\"\"\n",
    "    def function(self,x):\n",
    "        \"\"\"Activation function\"\"\"\n",
    "        raise NotImplementedError(\"This is only the base function, the implementation of this is on any of the other functions, for more information check the class DOCSTRING\")\n",
    "    def derivative(self,x):\n",
    "        \"\"\"Derivative of the activation function\"\"\"\n",
    "        raise NotImplementedError(\"This is only the base function, the implementation of this is on any of the other functions, for more information check the class DOCSTRING\")\n",
    "    def active(self):\n",
    "        raise NotImplementedError(\"This is only the base function, the implementation of this is on any of the other functions, for more information check the class DOCSTRING\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "vl52Q1Rl4sbo"
   },
   "outputs": [],
   "source": [
    "class Swish(activationFunction):\n",
    "    \"\"\"Scaled Exponential Linear Unit With a Shift function\"\"\"\n",
    "    def __init__(self, beta=1):\n",
    "        self.beta = beta\n",
    "    def function(self, x):\n",
    "        return x * (1 / (1 + np.exp(-self.beta * x)))\n",
    "    def derivative(self, x):\n",
    "        return (self.beta * self.function(x)) + (1 / (1 + np.exp(-self.beta * x))) * (1 - self.beta * self.function(x))\n",
    "    def active(self):\n",
    "        out = [-float('inf'), float('inf')]\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "8shE1T3W4yJz"
   },
   "outputs": [],
   "source": [
    "class Relu(activationFunction):\n",
    "    \"\"\"Rectified linear unit function (ReLU)\"\"\"\n",
    "    def function(self, x):\n",
    "        return np.maximum(0,x)\n",
    "    def derivative(self, x):\n",
    "        return np.where(x>0,1,0)\n",
    "    def active(self):\n",
    "        out = [0, float('inf')]\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "j2v-Y_2495Yb"
   },
   "outputs": [],
   "source": [
    "class Purelin(activationFunction):\n",
    "    \"\"\"Linear (Identity) function\"\"\"\n",
    "    def function(self,x):\n",
    "      return x\n",
    "    def derivative(self,x):\n",
    "      return np.ones_like(x)\n",
    "    def active(self):\n",
    "        out = [-float('inf'), float('inf')]\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "KuoUYoUuIG6P"
   },
   "outputs": [],
   "source": [
    "class Logsig(activationFunction):\n",
    "    \"\"\"Logistic function\"\"\"\n",
    "    def function(self, x):\n",
    "      return 1 / (1 + np.exp(-x))\n",
    "    def derivative(self,x):\n",
    "        return self.function(x) * (1 - self.function(x))\n",
    "    def active(self):\n",
    "        out = [-4.0, 4.0]\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "FbhNfFvmI9Cd"
   },
   "outputs": [],
   "source": [
    "class Tansig(activationFunction):\n",
    "    \"\"\"Hyperbolic function\"\"\"\n",
    "    def function(self,x):\n",
    "        return np.tanh(x)\n",
    "    def derivative(self,x):\n",
    "        return  1- np.tanh(x)**2\n",
    "    def active(self):\n",
    "        out = [-2, 2]\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "jIZd2WWFKioZ"
   },
   "outputs": [],
   "source": [
    "class Radbas(activationFunction):\n",
    "    \"\"\"Gaussian function\"\"\"\n",
    "    def function(self,x):\n",
    "        return np.exp(-x**2)\n",
    "    def derivative(self,x):\n",
    "        return -2 * x * np.exp(-x**2)\n",
    "    def active(self):\n",
    "        out = [-2, 2]\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "UTE_IxFnLIkU"
   },
   "outputs": [],
   "source": [
    "class Tribas(activationFunction):\n",
    "    \"\"\"Triangular basis function\"\"\"\n",
    "    def function(self, x):\n",
    "      return np.maximum(0, 1 - np.abs(x))\n",
    "    def derivative(self, x):\n",
    "      return np.where(np.abs(x) < 1, -1, 0)\n",
    "    def active(self):\n",
    "        out = [-1, 1]\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "lgC1nhgnLjeX"
   },
   "outputs": [],
   "source": [
    "class RadBasN(activationFunction):\n",
    "    \"\"\"Normalized radial basis function\"\"\"\n",
    "    def __init__(self, sigma=1):\n",
    "        \"\"\"\n",
    "        PARAMETERS\n",
    "        sigma : float by default 1\n",
    "        \"\"\"\n",
    "        self.sigma = sigma\n",
    "\n",
    "    def function(self, x):\n",
    "      return np.exp(-0.5 * (x / self.sigma)**2)\n",
    "    def derivative(self, x):\n",
    "      return -x / self.sigma**2 * np.exp(-0.5 * (x / self.sigma)**2)\n",
    "    def active(self):\n",
    "        out = [-2, 2]\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "yhHg-ZxGNLkp"
   },
   "outputs": [],
   "source": [
    "class HardLim(activationFunction):\n",
    "    \"\"\"Hard limit function\"\"\"\n",
    "    def function(self, x):\n",
    "        return np.where(x >= 0, 1, 0)\n",
    "    def derivative(self, x):\n",
    "        return np.zeros_like(x)\n",
    "    def active(self):\n",
    "        out = [0, 0]\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "Vx0uAWHENjcZ"
   },
   "outputs": [],
   "source": [
    "class HardLims(activationFunction):\n",
    "    \"\"\"Symmetric hard limit function\"\"\"\n",
    "    def function(self, x):\n",
    "        return np.where(x >= 0, 1, -1)\n",
    "    def derivative(self, x):\n",
    "        return np.zeros_like(x)\n",
    "    def active(self):\n",
    "        out = [0, 0]\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "s44mofomN2ju"
   },
   "outputs": [],
   "source": [
    "class SatLin(activationFunction):\n",
    "    \"\"\"Saturatin linear function\"\"\"\n",
    "    def function(self, x):\n",
    "        return np.clip(x, 0, None)\n",
    "\n",
    "    def derivative(self, x):\n",
    "        return np.where(x >= 0, 1, 0)\n",
    "    \n",
    "    def active(self):\n",
    "        out = [-0, 1]\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "3W5XynwgN-wb"
   },
   "outputs": [],
   "source": [
    "class SatLins(activationFunction):\n",
    "    \"\"\"Symmetric saturating function\"\"\"\n",
    "    def function(self, x):\n",
    "        return np.clip(x, -1, 1)\n",
    "\n",
    "    def derivative(self, x):\n",
    "        return np.where(np.logical_and(x >= -1, x <= 1), 1, 0)\n",
    "    \n",
    "    def active(self):\n",
    "        out = [-1, 1]\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "ra-GQVY6Pm9-"
   },
   "outputs": [],
   "source": [
    "class Softmax(activationFunction):\n",
    "    \"\"\"Normalized exponential function (softmax)\"\"\"\n",
    "    def function(self, x):\n",
    "        exps = np.exp(x)\n",
    "        sums = np.sum(exps)\n",
    "        return np.divide(exps, sums)\n",
    "    \n",
    "    def derivative(self, x):\n",
    "        raise NotImplementedError(\"La derivada de Softmax no se utiliza tÃ­picamente en el entrenamiento de redes neuronales.\")\n",
    "    \n",
    "    def active(self):\n",
    "        out = [-float('inf'), float('inf')]\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "pNnzzwWtP2yO"
   },
   "outputs": [],
   "source": [
    "class LeakyRelu(activationFunction):\n",
    "    \"\"\"Leaky rectified linear unit function (leakyRelu)\"\"\"\n",
    "    def function(self, x):\n",
    "        return np.where(x>0,x,1e-2*x)\n",
    "    def derivative(self, x):\n",
    "        return np.where(x>0,1,1e-2)\n",
    "    def active(self):\n",
    "        out = [-float('inf'), float('inf')]\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "Kj60iC_mP5aR"
   },
   "outputs": [],
   "source": [
    "class ELU(activationFunction):\n",
    "    \"\"\"Exponential Linear Unit function (ELU)\"\"\"\n",
    "    def __init__(self, alpha=1):\n",
    "        \"\"\"\n",
    "        PARAMETERS:\n",
    "        alpha = float by default 1\n",
    "        \"\"\"\n",
    "        self.alpha=alpha\n",
    "    def function(self, x):\n",
    "        return np.where(x>0,x,self.alpha*(np.exp(x)-1))\n",
    "    def derivative(self, x):\n",
    "        return np.where(x>0,1,self.alpha*np.exp(x))\n",
    "    def active(self):\n",
    "        out = [-float('inf'), float('inf')]\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "mpJ1CbgVP8hu"
   },
   "outputs": [],
   "source": [
    "class GELU(activationFunction):\n",
    "    \"\"\"Gaussian Error Linear Unit function (GELU)\"\"\"\n",
    "    def function(self, x):\n",
    "        return 0.5 * x * (1 + erf(x / np.sqrt(2)))\n",
    "    def derivative(self, x):\n",
    "        return 0.5 * (1 + erf(x / np.sqrt(2))) + (x / np.sqrt(2 * np.pi)) * np.exp(-0.5 * x**2)\n",
    "    def active(self):\n",
    "        out = [-float('inf'), float('inf')]\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "I0lFxTdgP-w9"
   },
   "outputs": [],
   "source": [
    "class PReLU(activationFunction):\n",
    "    \"\"\"Parametric rectified linear unit function (PReLU)\"\"\"\n",
    "    def __init__(self, alpha=1e-1):\n",
    "        \"\"\"\n",
    "        PARAMETERS\n",
    "        alpha : float by default 1e-1\n",
    "        \"\"\"\n",
    "        self.alpha=alpha\n",
    "    def function(self, x):\n",
    "        return np.where(x<0,self.alpha*x,x)\n",
    "    def derivative(self, x):\n",
    "        return np.where(x<0,self.alpha,1)\n",
    "    def active(self):\n",
    "        out = [-float('inf'), float('inf')]\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "Zfu4-hwtQAcV"
   },
   "outputs": [],
   "source": [
    "class SELU(activationFunction):\n",
    "    \"\"\"Scaled exponential linear unit function (SELU)\"\"\"\n",
    "    def __init__(self, lamb= 1.0507, alpha=1.67326):\n",
    "        \"\"\"\n",
    "        PARAMETERS\n",
    "        lamb : float by default 1.0507\n",
    "        alpha : float by default 1.67326\n",
    "        Both are suposed to be always that value so it's recomended to not change them\n",
    "        \"\"\"\n",
    "        self.lamb=lamb\n",
    "        self.alpha=alpha\n",
    "    def function(self, x):\n",
    "        return self.lamb * np.where(x<0, self.alpha*(np.exp(x)-1),x)\n",
    "    def derivative(self, x):\n",
    "        return self.lamb * np.where(x<0, self.alpha*np.exp(x),1)\n",
    "    def active(self):\n",
    "        out = [-float('inf'), float('inf')]\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "iw1z8DEkQC5j"
   },
   "outputs": [],
   "source": [
    "class SiLU(activationFunction):\n",
    "    \"\"\"Sigmoid linear unit function (SiLU)\"\"\"\n",
    "    def function(self, x):\n",
    "        return (x / (1 + np.exp(-x)))\n",
    "    def derivative(self, x):\n",
    "        return (1 + np.exp(-x) + x*np.exp(-x))/((1+np.exp(-x))**2)\n",
    "    def active(self):\n",
    "        out = [-float('inf'), float('inf')]\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "CIoQz-TqQFLg"
   },
   "outputs": [],
   "source": [
    "class Softplus(activationFunction):\n",
    "    \"\"\"Smooth approximation ReLU function\"\"\"\n",
    "    def function(self, x):\n",
    "        return np.log(1 + np.exp(x))\n",
    "    def derivative(self, x):\n",
    "        return 1 / (1+np.exp(-x))\n",
    "    def active(self):\n",
    "        out = [-float('inf'), float('inf')]\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Funciones de error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ErrorFunctions:\n",
    "    @staticmethod\n",
    "    def MSE(y_true, y_pred):\n",
    "        \"\"\"\n",
    "        Calculate the mean squared error between true and predicted values.\n",
    "\n",
    "        Parameters:\n",
    "        y_true: numpy.ndarray\n",
    "            True values\n",
    "        y_pred: numpy.ndarray\n",
    "            Predicted values\n",
    "\n",
    "        Returns:\n",
    "        float\n",
    "            Mean squared error\n",
    "        \"\"\"\n",
    "        y_true = np.array(y_true)\n",
    "        y_pred = np.array(y_pred)\n",
    "        return np.mean((y_true - y_pred) ** 2)\n",
    "    \n",
    "    @staticmethod\n",
    "    def MAE(y_true, y_pred):\n",
    "        \"\"\"\n",
    "        Calculate the mean absolute error between true and predicted values.\n",
    "\n",
    "        Parameters:\n",
    "        y_true: numpy.ndarray\n",
    "            True values\n",
    "        y_pred: numpy.ndarray\n",
    "            Predicted values\n",
    "\n",
    "        Returns:\n",
    "        float\n",
    "            Mean absolute error\n",
    "        \"\"\"\n",
    "        y_true = np.array(y_true)\n",
    "        y_pred = np.array(y_pred)\n",
    "        return np.mean(np.abs(y_true - y_pred))\n",
    "\n",
    "    @staticmethod\n",
    "    def SSE(y_true, y_pred):\n",
    "        \"\"\"\n",
    "        Calculate the sum of squared errors between true and predicted values.\n",
    "\n",
    "        Parameters:\n",
    "        y_true: numpy.ndarray\n",
    "            True values\n",
    "        y_pred: numpy.ndarray\n",
    "            Predicted values\n",
    "\n",
    "        Returns:\n",
    "        float\n",
    "            Sum of squared errors\n",
    "        \"\"\"\n",
    "        y_true = np.array(y_true)\n",
    "        y_pred = np.array(y_pred)\n",
    "        return np.sum((y_true - y_pred) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QFBX6lkR44kf"
   },
   "source": [
    "# ESTRUCTURA DE LA RED NEURONAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    \"\"\"Class for the structure of a Neural Network\"\"\"\n",
    "    def __init__(self, input_size:int, layer_sizes:list[int], output_size:int, \n",
    "                 activation_funcs:list['activationFunction'], wInit:str='random',\n",
    "                 dropout_rate:float=0)->None:\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        input_size: int \n",
    "            Defines the size of the input layer\n",
    "        layer_sizes: int array \n",
    "            Defines the sizes of the ocult layers\n",
    "        output_size: int \n",
    "            Defines the size of the output layer\n",
    "        activation_funcs: activationFunction class array \n",
    "            Defines the activation function per layer\n",
    "        \"\"\"\n",
    "        self.input_size = input_size\n",
    "        self.layer_sizes = [input_size] + layer_sizes + [output_size]  # Incluir el tamaÃ±o de la capa de entrada y de salida\n",
    "        self.output_size = output_size\n",
    "        self.activation_funcs = activation_funcs\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.num_layers = len(self.layer_sizes)\n",
    "        self.weights = self._initializeWeights(wInit)\n",
    "        self.n_outputs = []  # Lista para almacenar las salidas antes de la funciÃ³n de activaciÃ³n\n",
    "        self.a_outputs = []\n",
    "        self.dropout_masks = []\n",
    "\n",
    "    \n",
    "    def _initializeWeights(self, wInit):\n",
    "        \"\"\"\n",
    "        Inicializa los pesos de la red neuronal ya sea de manera random o mediante el metodo nguyen widraw\n",
    "        \n",
    "        :return: Lista de matrices de pesos como np.ndarrar\n",
    "        \"\"\"\n",
    "        weights = []\n",
    "        if wInit == 'random':\n",
    "            for i in range(self.num_layers - 1):\n",
    "                W = np.random.randn(self.layer_sizes[i] + 1, self.layer_sizes[i+1]) # +1 para incluir los sesgos\n",
    "                weights.append(W)\n",
    "        elif wInit == 'nguyen':\n",
    "            for i in range(self.num_layers - 1):\n",
    "                ni = self.layer_sizes[i]\n",
    "                no = self.layer_sizes[i+1]\n",
    "                g = (0.7*no) ** (1/ni)\n",
    "                active = self.activation_funcs[i].active()\n",
    "                if not np.isinf(active[0]) and not np.isinf(active[1]):\n",
    "                    W = np.random.randn(no, ni)\n",
    "                    W = W / np.linalg.norm(W, axis=1, keepdims=True)  # Normalizacion\n",
    "                    W = g * W\n",
    "                    beta = np.linspace(active[0], active[1], no).reshape(-1, 1)\n",
    "                    bias = g * (np.sign(W[:, 0]).reshape(-1, 1) * beta)\n",
    "                    W = np.hstack([W, bias])\n",
    "                    weights.append(W.T)\n",
    "                else:\n",
    "                    W = g * np.random.randn(ni+1,no)\n",
    "                    weights.append(W)\n",
    "        else:\n",
    "            raise KeyError(\"No se reconoce el inicializador\")\n",
    "        return np.array(weights, dtype = object)\n",
    "    \n",
    "    def forwardPass(self, inputs, training=True):\n",
    "        A = np.hstack([inputs, np.ones((inputs.shape[0], 1))])\n",
    "        self.n_outputs = [inputs]\n",
    "        self.a_outputs = [A]\n",
    "        self.dropout_masks = []\n",
    "\n",
    "        for i, weight in enumerate(self.weights):\n",
    "            Z = np.dot(A, weight)\n",
    "            self.n_outputs.append(Z)\n",
    "            A = self.activation_funcs[i].function(Z)\n",
    "            \n",
    "            if self.dropout_rate > 0 and training and i < len(self.weights) - 1:  # Dropout en todo menos la ultima capa y solo durante el entrenamiento\n",
    "                dropout_mask = np.random.binomial(1, 1 - self.dropout_rate, size=A.shape)\n",
    "                A *= dropout_mask\n",
    "                self.dropout_masks.append(dropout_mask)\n",
    "            elif not training and i < len(self.weights) - 1:  # Escalar datos durante la inferencia (no entrenando)\n",
    "                A *= (1 - self.dropout_rate)\n",
    "            \n",
    "            A = np.hstack([A, np.ones((A.shape[0], 1))])\n",
    "            self.a_outputs.append(A)\n",
    "        return A[:, :-1]\n",
    "    \"\"\"    \n",
    "    def forwardPass(self, inputs):\n",
    "        A = np.hstack([inputs,np.ones((inputs.shape[0], 1))])\n",
    "        self.n_outputs = [inputs] #La primera n siempre es igual a los inputs\n",
    "        self.a_outputs = [A]\n",
    "        # Iterar sobre cada capa de la red\n",
    "        for weight in self.weights:\n",
    "            # CÃ¡lculo del producto punto entre los pesos y el input aumentado por el sesgo\n",
    "            Z = np.dot(A,weight)\n",
    "            self.n_outputs.append(Z)\n",
    "            # AplicaciÃ³n de la funciÃ³n de activaciÃ³n correspondiente\n",
    "            A = self.activation_funcs[len(self.a_outputs)-1].function(Z)\n",
    "            A = np.hstack([A,np.ones((A.shape[0], 1))])\n",
    "            self.a_outputs.append(A)  \n",
    "        return A[:,:-1] # TODO MENOS LA COLUMNA AUMENTADA\n",
    "    \"\"\"\n",
    "    def backwardPass(self, targets):\n",
    "        #gradients = np.array([])\n",
    "        gradients = []\n",
    "        e = targets - self.a_outputs[-1][:,:-1]\n",
    "        ge = -2*e\n",
    "        delta = ge * self.activation_funcs[-1].derivative(np.array(self.n_outputs[-1]))\n",
    "        ae = self.a_outputs[-2] #El metodo forward pass deja a_outputs aumentado\n",
    "        ge = np.dot(ae.T,delta)\n",
    "        gradients.append(ge)\n",
    "        \n",
    "        for i in range(self.num_layers-2, 0, -1): \n",
    "            fdx = self.activation_funcs[i].derivative(np.array(self.n_outputs[i]))\n",
    "            delta = fdx * np.dot(delta,self.weights[i][:-1].T)\n",
    "            \n",
    "            if self.dropout_rate > 0 and self.dropout_masks: #Si existe alguna mascara de dropout aplicarla\n",
    "                delta *= self.dropout_masks.pop()  # Apply dropout mask\n",
    "            \n",
    "            ae = self.a_outputs[i-1]\n",
    "            ge = np.dot(ae.T,delta)\n",
    "            gradients.insert(0,ge)\n",
    "        return gradients\n",
    "            \n",
    "    def error(self,targets,error_func):\n",
    "        \"\"\"\n",
    "        Calculate the error based on the inputs, outputs, and error function specified.\n",
    "\n",
    "        Parameters:\n",
    "        inputs: numpy.ndarray\n",
    "            Input data\n",
    "        outputs: numpy.ndarray\n",
    "            Output data\n",
    "        error_func: function\n",
    "            Error function to use (e.g., mean squared error, mean absolute error, etc.)\n",
    "\n",
    "        Returns:\n",
    "        float\n",
    "            Error value calculated using the specified error function.\n",
    "        \"\"\"\n",
    "        predicted_outputs = self.a_outputs[-1][:,:-1]\n",
    "        return error_func(targets, predicted_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Optimizadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer():\n",
    "    \"\"\"\n",
    "    Class for the optimizers based on two different algorithms\n",
    "\n",
    "    RMSProp()\n",
    "    AdamW() \n",
    "    \"\"\"\n",
    "    def __init__(self,lr:float,maxEpochs:int,goal:float,mingrad:float,nn: NeuralNetwork,\n",
    "                 inputs,targets,error_fun,show:int =1,consecutive_epochs:int =10,\n",
    "                 num_batch: int=1)->None:  \n",
    "        self.nn = nn\n",
    "        self.name = \"DEFAULT\"\n",
    "        self.lr = lr\n",
    "        self.num_batch = num_batch\n",
    "        self.maxEpochs = maxEpochs\n",
    "        self.goal = goal\n",
    "        self.mingrad = mingrad\n",
    "        self.show = show\n",
    "        self.inputs = inputs\n",
    "        self.targets = targets\n",
    "        self.error_fun = error_fun\n",
    "        self.consecutive_epochs = consecutive_epochs\n",
    "        \n",
    "        \n",
    "    def optimize(self):\n",
    "        this = self.name\n",
    "        stop = \"\"\n",
    "        epochs = []\n",
    "        perfs  = []\n",
    "        consecutive_rise = 0  # Contador para el nÃºmero de Ã©pocas consecutivas en las que el rendimiento ha subido\n",
    "        prev_perf = float('inf')\n",
    "        print(\"\\n\")\n",
    "        # Train\n",
    "        for epoch in range(self.maxEpochs+1):\n",
    "            # Performance and Gradient\n",
    "            _ = self.nn.forwardPass(self.inputs)\n",
    "            gX = self.nn.backwardPass(self.targets)\n",
    "            perf = self.nn.error(self.targets, self.error_fun)            \n",
    "            \n",
    "            # Aplanar y concatenar los gradientes en un solo vector\n",
    "            gX_flattened = np.concatenate([grad.flatten() for grad in gX])\n",
    "            normgX = np.linalg.norm(gX_flattened)  \n",
    "            #normgX = np.linalg.norm(gX)  \n",
    "            \n",
    "            # Stopping criteria\n",
    "            if np.all(perf <= self.goal):\n",
    "                stop = \"Performance goal met\"\n",
    "            elif epoch == self.maxEpochs:\n",
    "                stop = \"Maximum epoch reached, performance goal was not met\"\n",
    "            elif normgX < self.mingrad:\n",
    "                stop = \"Minimum gradient reached, performance goal was not met\"\n",
    "            elif perf >= prev_perf:\n",
    "                consecutive_rise += 1\n",
    "                if consecutive_rise >= self.consecutive_epochs:\n",
    "                    stop = f\"Performance has risen for {self.consecutive_epochs} consecutive epochs\"\n",
    "            elif perf < prev_perf:\n",
    "                consecutive_rise = 0\n",
    "    \n",
    "            prev_perf = perf\n",
    "\n",
    "            # Progress\n",
    "            if (np.fmod(epoch,self.show) == 0 or len(stop) != 0):\n",
    "                print(this,end = \": \")\n",
    "                if np.isfinite(self.maxEpochs):\n",
    "                    print(\"Epoch \",epoch, \"/\", self.maxEpochs,end = \" \")\n",
    "                if np.isfinite(self.goal):\n",
    "                    print(\", Performance %8.3e\" % perf, \"/\", self.goal, end = \" \")\n",
    "                if np.isfinite(self.mingrad):\n",
    "                    print(\", Gradient %8.3e\" % normgX, \"/\", self.mingrad)\n",
    "\n",
    "                \n",
    "                if len(stop) != 0:\n",
    "                    print(\"\\n\",this,\":\",stop,\"\\n\")\n",
    "                    break\n",
    "            epochs = np.append(epochs,epoch)\n",
    "            perfs = np.append(perfs,perf)\n",
    "            self.train(gX_flattened)\n",
    "            \n",
    "        return perfs, epochs\n",
    "    def train(self,gX):\n",
    "        raise NotImplementedError(\"No se ha definido el optimizador, esta es la clase base\")\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RmsProp(Optimizer):\n",
    "    def __init__(self, nn: NeuralNetwork, inputs, targets,lr: float =1e-3, num_batch: int =1, maxEpochs: int =500, \n",
    "                 goal: float =1e-8,mingrad: float =1e-11, show:int =1, error_fun=ErrorFunctions.SSE, \n",
    "                 consecutive_epochs: int=10,WDecay:float=0,alpha:float=0.99,centered:bool=False,\n",
    "                 momentum:float=0.6,epsilon:float=1e-9) -> None:\n",
    "        super().__init__(lr,maxEpochs,goal,mingrad,nn,inputs,targets,error_fun,show,consecutive_epochs,num_batch)\n",
    "        self.name = \"trainRMSPROP\"\n",
    "        self.epsilon = epsilon\n",
    "        self.v = np.zeros_like(np.concatenate([w.flatten() for w in nn.weights]))  # Vector de acumulaciÃ³n de gradientes\n",
    "        self.vh = 0\n",
    "        self.b = 0\n",
    "        self.gAvg = 0\n",
    "        self.WDecay = WDecay\n",
    "        self.alpha = alpha\n",
    "        self.centered = centered\n",
    "        self.momentum = momentum\n",
    "\n",
    "    def train(self, gX):        \n",
    "        if self.WDecay != 0:\n",
    "            gX = gX + gX*self.WDecay\n",
    "        self.v = self.alpha*self.v + ((1-self.alpha)*(gX**2))\n",
    "        self.vh = self.v\n",
    "        if self.centered:\n",
    "            self.gAvg = self.gAvg*self.alpha + ((1-self.alpha)*gX)\n",
    "            self.vh = self.vh - self.gAvg**2\n",
    "        if self.momentum > 0:\n",
    "            self.b = self.momentum*self.b + gX/((self.vh**(1/2))+self.epsilon)\n",
    "            update = self.lr*self.b\n",
    "            #self.nn.weights += dX\n",
    "        else:\n",
    "            update = self.lr*(gX/((self.vh**(1/2))+1e-8))\n",
    "            #self.nn.weights += dX\n",
    "        \n",
    "        # Actualizar pesos\n",
    "        start = 0\n",
    "        for i, w in enumerate(self.nn.weights):\n",
    "            shape = w.shape\n",
    "            size = np.prod(shape)\n",
    "            grad_update = update[start:start+size].reshape(shape)\n",
    "            self.nn.weights[i] -= grad_update\n",
    "            start += size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "\n",
    "def main():\n",
    "    activationFunction()\n",
    "    neural_network = NeuralNetwork(input_size = 2,\n",
    "                                layer_sizes = [50,50,30],\n",
    "                                output_size = 2,\n",
    "                                activation_funcs = [Logsig(),Logsig(),Relu(),Purelin()],\n",
    "                                wInit = 'nguyen',\n",
    "                                dropout_rate=0.1)\n",
    "\n",
    "    # Carga el archivo .mat\n",
    "    data = loadmat('engine_dataset.mat')\n",
    "    inputs = data['engineInputs'].T\n",
    "    targets = data['engineTargets'].T\n",
    "    for weight in neural_network.weights:\n",
    "        print(f\"Tamano de los pesos: {weight.shape}\")\n",
    "    \n",
    "    Optimizador = RmsProp(nn=neural_network,\n",
    "                          inputs=inputs,\n",
    "                          targets=targets,\n",
    "                          lr=1e-3,\n",
    "                          maxEpochs=5000,\n",
    "                          show=500,\n",
    "                          consecutive_epochs=10,\n",
    "                          mingrad=1e-8,\n",
    "                          error_fun=ErrorFunctions.MSE)\n",
    "    \n",
    "    perfs,epochs = Optimizador.optimize()\n",
    "    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(epochs, perfs)\n",
    "    plt.title('Performance')\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    #print(f\"Pesos despues: {neural_network.weights}\")\n",
    "    outputs = neural_network.forwardPass(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DO MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamano de los pesos: (3, 50)\n",
      "Tamano de los pesos: (51, 50)\n",
      "Tamano de los pesos: (51, 30)\n",
      "Tamano de los pesos: (31, 2)\n",
      "\n",
      "\n",
      "trainRMSPROP: Epoch  0 / 5000 , Performance 9.849e+05 / 1e-08 , Gradient 2.308e+08 / 1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_33824\\3040260320.py:4: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainRMSPROP: Epoch  500 / 5000 , Performance 2.628e+05 / 1e-08 , Gradient 2.037e+08 / 1e-08\n",
      "trainRMSPROP: Epoch  1000 / 5000 , Performance 2.546e+05 / 1e-08 , Gradient 1.392e+08 / 1e-08\n",
      "trainRMSPROP: Epoch  1500 / 5000 , Performance 2.119e+05 / 1e-08 , Gradient 7.461e+08 / 1e-08\n",
      "trainRMSPROP: Epoch  2000 / 5000 , Performance 1.807e+05 / 1e-08 , Gradient 3.365e+08 / 1e-08\n",
      "trainRMSPROP: Epoch  2500 / 5000 , Performance 1.761e+05 / 1e-08 , Gradient 2.408e+09 / 1e-08\n",
      "trainRMSPROP: Epoch  3000 / 5000 , Performance 1.733e+05 / 1e-08 , Gradient 1.879e+09 / 1e-08\n",
      "trainRMSPROP: Epoch  3500 / 5000 , Performance 1.769e+05 / 1e-08 , Gradient 2.652e+09 / 1e-08\n",
      "trainRMSPROP: Epoch  4000 / 5000 , Performance 1.728e+05 / 1e-08 , Gradient 5.718e+08 / 1e-08\n",
      "trainRMSPROP: Epoch  4500 / 5000 , Performance 1.776e+05 / 1e-08 , Gradient 8.461e+08 / 1e-08\n",
      "trainRMSPROP: Epoch  5000 / 5000 , Performance 1.747e+05 / 1e-08 , Gradient 1.661e+09 / 1e-08\n",
      "\n",
      " trainRMSPROP : Maximum epoch reached, performance goal was not met \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
